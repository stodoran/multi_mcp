# Multi-MCP Configuration
# =======================
# Copy this file to .env and fill in your API keys:
#   cp .env.example .env
#
# At least one API key is required.

# =============================================================================
# API Keys
# =============================================================================

# OpenAI (for gpt-5-mini, gpt-5.1, gpt-5.2, codex models)
# OPENAI_API_KEY=sk-...

# Anthropic (for claude-haiku, claude-sonnet, claude-opus)
# ANTHROPIC_API_KEY=sk-ant-...

# Google (for gemini-2.5-pro, gemini-3-flash, gemini-3)
# GEMINI_API_KEY=...

# OpenRouter (for deepseek, qwen, and other models)
# OPENROUTER_API_KEY=sk-or-...

# Azure OpenAI (optional - alternative to OpenAI)
# AZURE_API_KEY=...
# AZURE_API_BASE=https://your-resource.openai.azure.com/
# AZURE_API_VERSION=2025-04-01-preview

# AWS Bedrock (optional - for bedrock models)
# AWS_ACCESS_KEY_ID=...
# AWS_SECRET_ACCESS_KEY=...
# AWS_REGION_NAME=us-east-1

# =============================================================================
# Runtime Settings (optional - sensible defaults provided)
# =============================================================================

# Default model for single-model tools
DEFAULT_MODEL=gemini-3

# Default models for multi-model compare (comma-separated or JSON array)
DEFAULT_MODEL_LIST=codex,gemini-3,sonnet

# Default temperature (0.0-1.0)
# DEFAULT_TEMPERATURE=0.2

# Logging level (DEBUG, INFO, WARNING, ERROR)
# LOG_LEVEL=INFO

# =============================================================================
# Advanced Settings (optional)
# =============================================================================

# Retry configuration
# MAX_RETRIES=3
# MODEL_TIMEOUT_SECONDS=300.0

# File processing limits
# MAX_FILES_PER_REVIEW=100
# MAX_FILE_SIZE_KB=50

# Response size limit before consolidation
# MAX_CODEREVIEW_RESPONSE_SIZE=60000

# Artifact logging directory (relative to base_path or absolute)
# ARTIFACTS_DIR=
